{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 07.2 — Multi-task Structured Classification with a Shared MLP\n",
        "\n",
        "This notebook introduces **07.2**, a structured multi-task model that jointly predicts speaker\n",
        "identity, interaction context, and pre/post-vocalization behaviors from a shared acoustic\n",
        "representation. Rather than training each label independently, the model learns a common trunk\n",
        "that supports multiple, semantically related prediction heads.\n",
        "\n",
        "**Key design choices:**\n",
        "- **Shared MLP trunk with multiple heads** to exploit correlations between identity, context, and behavior.\n",
        "- **Per-task class-weighted losses** to address severe imbalance, especially for context and action labels.\n",
        "- **Fixed-length acoustic features (1152-D)** consistent with earlier models to isolate the effect of structure.\n",
        "\n",
        "**Objective:** improve context and action prediction through shared supervision and motivate\n",
        "sequence-level and language-style modeling in later stages."
      ],
      "metadata": {
        "id": "6JH0yqrtPlqi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Tuple, Any\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n"
      ],
      "metadata": {
        "id": "53Jllk-nYh8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construct feature matrix and multi-task labels\n",
        "\n",
        "This cell builds a fixed-dimensional feature matrix and aligned label arrays for all supervised\n",
        "tasks. Each example contributes multiple labels simultaneously, and only samples with complete\n",
        "acoustic features are retained to ensure consistent input dimensionality.\n"
      ],
      "metadata": {
        "id": "SEu4VYqfdUoH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collect_features_and_labels_A2(\n",
        "    ann: pd.DataFrame,\n",
        "    use_ast: bool = True,\n",
        "    use_kmeans_tokens: bool = True,\n",
        "    use_vqvae_tokens: bool = True,\n",
        "    kmeans_clusters: int = 128,\n",
        "    vqvae_codes: int = 256,\n",
        "    expected_dim: int = 1152,  # 768 + 128 + 256\n",
        ") -> Tuple[np.ndarray, Dict[str, List[Any]]]:\n",
        "    \"\"\"\n",
        "    Builds X and labels_raw dict aligned to your annotations_10k.csv columns.\n",
        "    Ensures fixed feature size by using the A0-style bincount(minlength=...).\n",
        "    \"\"\"\n",
        "\n",
        "    stems = ann[\"File Name\"].apply(lambda s: Path(str(s)).stem)\n",
        "\n",
        "    X_list: List[np.ndarray] = []\n",
        "    labels_raw: Dict[str, List[Any]] = {\n",
        "        \"emitter\": [],\n",
        "        \"addressee\": [],\n",
        "        \"context\": [],\n",
        "        \"emitter_pre\": [],\n",
        "        \"addressee_pre\": [],\n",
        "        \"emitter_post\": [],\n",
        "        \"addressee_post\": [],\n",
        "    }\n",
        "\n",
        "    # Exact column names\n",
        "    COL_EMITTER = \"Emitter\"\n",
        "    COL_ADDRESSEE = \"Addressee\"\n",
        "    COL_CONTEXT = \"Context\"\n",
        "    COL_E_PRE = \"Emitter pre-vocalization action\"\n",
        "    COL_A_PRE = \"Addressee pre-vocalization action\"\n",
        "    COL_E_POST = \"Emitter post-vocalization action\"\n",
        "    COL_A_POST = \"Addressee post-vocalization action\"\n",
        "\n",
        "    skipped_missing = 0\n",
        "    skipped_dim = 0\n",
        "\n",
        "    for fn, stem, row in zip(ann[\"File Name\"], stems, ann.to_dict(\"records\")):\n",
        "        parts: List[np.ndarray] = []\n",
        "\n",
        "        if use_ast:\n",
        "            ast_vec = _load_ast_vector(stem)\n",
        "            if ast_vec is None:\n",
        "                skipped_missing += 1\n",
        "                continue\n",
        "            parts.append(ast_vec)\n",
        "\n",
        "        if use_kmeans_tokens:\n",
        "            km_hist = _load_kmeans_hist(stem, n_clusters=kmeans_clusters)\n",
        "            if km_hist is None:\n",
        "                skipped_missing += 1\n",
        "                continue\n",
        "            parts.append(km_hist)\n",
        "\n",
        "        if use_vqvae_tokens:\n",
        "            vq_hist = _load_vqvae_hist(stem, n_codes=vqvae_codes)\n",
        "            if vq_hist is None:\n",
        "                skipped_missing += 1\n",
        "                continue\n",
        "            parts.append(vq_hist)\n",
        "\n",
        "        feat_vec = np.concatenate(parts).astype(np.float32)\n",
        "\n",
        "        # Hard guard\n",
        "        if expected_dim is not None and feat_vec.shape[0] != expected_dim:\n",
        "            skipped_dim += 1\n",
        "            continue\n",
        "\n",
        "        X_list.append(feat_vec)\n",
        "\n",
        "        # Labels as strings (LabelEncoder-friendly)\n",
        "        labels_raw[\"emitter\"].append(str(row.get(COL_EMITTER, \"\")))\n",
        "        labels_raw[\"addressee\"].append(str(row.get(COL_ADDRESSEE, \"\")))\n",
        "        labels_raw[\"context\"].append(str(row.get(COL_CONTEXT, \"\")))\n",
        "\n",
        "        labels_raw[\"emitter_pre\"].append(str(row.get(COL_E_PRE, \"\")))\n",
        "        labels_raw[\"addressee_pre\"].append(str(row.get(COL_A_PRE, \"\")))\n",
        "        labels_raw[\"emitter_post\"].append(str(row.get(COL_E_POST, \"\")))\n",
        "        labels_raw[\"addressee_post\"].append(str(row.get(COL_A_POST, \"\")))\n",
        "\n",
        "    if not X_list:\n",
        "        raise RuntimeError(\"No feature vectors constructed. Check feature directories and filenames.\")\n",
        "\n",
        "    X = np.vstack(X_list)\n",
        "    print(\n",
        "        f\"Built A2 features for {X.shape[0]} examples; dim={X.shape[1]}. \"\n",
        "        f\"Skipped missing={skipped_missing}, skipped_dim={skipped_dim}.\"\n",
        "    )\n",
        "    return X, labels_raw\n",
        "\n",
        "\n",
        "X_all, labels_raw = collect_features_and_labels_A2(\n",
        "    ann,\n",
        "    use_ast=True,\n",
        "    use_kmeans_tokens=True,\n",
        "    use_vqvae_tokens=True,\n",
        "    kmeans_clusters=128,\n",
        "    vqvae_codes=256,\n",
        "    expected_dim=1152,\n",
        ")\n",
        "\n",
        "X_all.shape, {k: len(set(v)) for k, v in labels_raw.items()}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Frl1rGcKZR3F",
        "outputId": "758db4a4-d601-45c2-ab5a-e799e339f302"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built A2 features for 10000 examples; dim=1152. Skipped missing=0, skipped_dim=0.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10000, 1152),\n",
              " {'emitter': 10,\n",
              "  'addressee': 28,\n",
              "  'context': 12,\n",
              "  'emitter_pre': 4,\n",
              "  'addressee_pre': 4,\n",
              "  'emitter_post': 5,\n",
              "  'addressee_post': 5})"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Label encoding and class imbalance handling\n",
        "\n",
        "This cell encodes string labels into integer IDs, safely ignores missing annotations, and computes\n",
        "balanced class weights per task. These utilities are critical for handling severe class imbalance\n",
        "without discarding partially labeled samples.\n"
      ],
      "metadata": {
        "id": "WmvNRXo_dgPV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IGNORE_INDEX = -100\n",
        "\n",
        "def encode_labels(y_raw, missing_values=None):\n",
        "    \"\"\"\n",
        "    Encode labels with LabelEncoder; map missing_values to IGNORE_INDEX.\n",
        "    \"\"\"\n",
        "    y_raw = np.asarray(y_raw, dtype=object)\n",
        "\n",
        "    missing_mask = np.zeros(len(y_raw), dtype=bool)\n",
        "    if missing_values is not None:\n",
        "        missing_values = set(missing_values)\n",
        "        missing_mask = np.array([v in missing_values for v in y_raw], dtype=bool)\n",
        "\n",
        "    le = LabelEncoder()\n",
        "    y_fit = y_raw[~missing_mask]\n",
        "\n",
        "    if len(y_fit) == 0:\n",
        "        le.classes_ = np.array([], dtype=object)\n",
        "        y_enc = np.full(len(y_raw), IGNORE_INDEX, dtype=np.int64)\n",
        "        return y_enc, le\n",
        "\n",
        "    le.fit(y_fit)\n",
        "    y_enc = np.full(len(y_raw), IGNORE_INDEX, dtype=np.int64)\n",
        "    y_enc[~missing_mask] = le.transform(y_raw[~missing_mask]).astype(np.int64)\n",
        "    return y_enc, le\n",
        "\n",
        "\n",
        "def compute_class_weights(y_enc: np.ndarray, num_classes: int, device: torch.device) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Balanced weights: n / (k * count_c), ignoring IGNORE_INDEX.\n",
        "    \"\"\"\n",
        "    y = y_enc[y_enc != IGNORE_INDEX]\n",
        "    counts = np.bincount(y, minlength=num_classes).astype(np.float32)\n",
        "    counts[counts == 0] = 1.0\n",
        "    n = float(len(y))\n",
        "    k = float(num_classes)\n",
        "    weights = n / (k * counts)\n",
        "    return torch.tensor(weights, dtype=torch.float32, device=device)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def macro_f1_ignore_missing(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
        "    mask = (y_true != IGNORE_INDEX)\n",
        "    if mask.sum() == 0:\n",
        "        return float(\"nan\")\n",
        "    return f1_score(y_true[mask], y_pred[mask], average=\"macro\")"
      ],
      "metadata": {
        "id": "R60McVZgZVH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyTorch dataset for multi-task learning\n",
        "\n",
        "This dataset wraps the shared feature vectors and returns a dictionary of task-specific labels for\n",
        "each example. The structure supports a single forward pass with independent loss computation per\n",
        "task head.\n"
      ],
      "metadata": {
        "id": "m5gmPP8qdiHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiTaskDataset(Dataset):\n",
        "    def __init__(self, X: np.ndarray, y_dict: dict):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32)\n",
        "        self.y_dict = {k: torch.tensor(v, dtype=torch.long) for k, v in y_dict.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.X.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        out = {\"X\": self.X[idx]}\n",
        "        for k in self.y_dict:\n",
        "            out[k] = self.y_dict[k][idx]\n",
        "        return out"
      ],
      "metadata": {
        "id": "-Ty_7J-dZYpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-head MLP architecture\n",
        "\n",
        "This model uses a shared MLP trunk to learn a common acoustic representation, followed by\n",
        "task-specific linear heads. The design encourages shared structure while allowing specialization\n",
        "across identity, context, and action labels.\n"
      ],
      "metadata": {
        "id": "a4nh_PiHdk5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadMLP(nn.Module):\n",
        "    def __init__(self, input_dim: int, hidden_dims=(512,), dropout=0.3, head_dims=None):\n",
        "        super().__init__()\n",
        "        if head_dims is None:\n",
        "            head_dims = {}\n",
        "\n",
        "        layers = []\n",
        "        prev = input_dim\n",
        "        for h in hidden_dims:\n",
        "            layers.append(nn.Linear(prev, h))\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.Dropout(dropout))\n",
        "            prev = h\n",
        "\n",
        "        self.trunk = nn.Sequential(*layers)\n",
        "        self.heads = nn.ModuleDict({k: nn.Linear(prev, c) for k, c in head_dims.items()})\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.trunk(x)\n",
        "        return {k: head(z) for k, head in self.heads.items()}"
      ],
      "metadata": {
        "id": "YGjkkMw_ZaWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and evaluation loops\n",
        "\n",
        "This cell defines the multi-task training loop with weighted, task-specific losses and an evaluation\n",
        "routine that reports macro-F1 while ignoring missing labels. Metrics are computed per task to\n",
        "diagnose where learning is most effective.\n"
      ],
      "metadata": {
        "id": "WyI7GKn9dns3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, loader, optim, criterions, loss_weights, device):\n",
        "    model.train()\n",
        "    total = 0.0\n",
        "    n = 0\n",
        "\n",
        "    for batch in loader:\n",
        "        X = batch[\"X\"].to(device)\n",
        "        optim.zero_grad()\n",
        "\n",
        "        logits = model(X)\n",
        "        loss = 0.0\n",
        "\n",
        "        for task, logit in logits.items():\n",
        "            y = batch[task].to(device)\n",
        "            loss_task = criterions[task](logit, y)\n",
        "            loss = loss + loss_weights.get(task, 1.0) * loss_task\n",
        "\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "\n",
        "        bs = X.size(0)\n",
        "        total += loss.item() * bs\n",
        "        n += bs\n",
        "\n",
        "    return total / max(n, 1)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, tasks, device):\n",
        "    model.eval()\n",
        "\n",
        "    all_true = {t: [] for t in tasks}\n",
        "    all_pred = {t: [] for t in tasks}\n",
        "\n",
        "    for batch in loader:\n",
        "        X = batch[\"X\"].to(device)\n",
        "        logits = model(X)\n",
        "\n",
        "        for t in tasks:\n",
        "            y = batch[t].cpu().numpy()\n",
        "            pred = torch.argmax(logits[t], dim=1).cpu().numpy()\n",
        "            all_true[t].append(y)\n",
        "            all_pred[t].append(pred)\n",
        "\n",
        "    out = {}\n",
        "    for t in tasks:\n",
        "        y_true = np.concatenate(all_true[t])\n",
        "        y_pred = np.concatenate(all_pred[t])\n",
        "        out[t] = {\n",
        "            \"macro_f1\": macro_f1_ignore_missing(y_true, y_pred),\n",
        "            \"y_true\": y_true,\n",
        "            \"y_pred\": y_pred,\n",
        "        }\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "1W6z4JCHZc2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run multi-task experiments\n",
        "\n",
        "This function performs train/test splitting, feature scaling, and a small hyperparameter search\n",
        "over model size and learning rate. Models are selected based on context macro-F1, the most\n",
        "challenging and informative task.\n"
      ],
      "metadata": {
        "id": "vvIXbRFkdqoD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_a2_multitask_mlp(\n",
        "    X_all: np.ndarray,\n",
        "    labels_raw: dict,\n",
        "    hidden_grid=((512,), (512, 256)),\n",
        "    lr_grid=(1e-3, 3e-4),\n",
        "    dropout=0.3,\n",
        "    batch_size=128,\n",
        "    epochs=30,\n",
        "    random_state=42,\n",
        "    select_by=\"context\",  # \"context\" or \"avg\"\n",
        "):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    missing_vals = {\"\", \"NA\", \"NaN\", \"None\", None, np.nan}\n",
        "\n",
        "    # Encode labels per head\n",
        "    y_enc = {}\n",
        "    encoders = {}\n",
        "    for k, y in labels_raw.items():\n",
        "        yk, le = encode_labels(y, missing_values=missing_vals)\n",
        "        y_enc[k] = yk\n",
        "        encoders[k] = le\n",
        "\n",
        "    # Stratify on context (primary target for improvement)\n",
        "    y_strat = y_enc[\"context\"]\n",
        "    X_train, X_test, idx_train, idx_test = train_test_split(\n",
        "        X_all, np.arange(len(X_all)),\n",
        "        test_size=0.2,\n",
        "        random_state=random_state,\n",
        "        stratify=y_strat,\n",
        "    )\n",
        "\n",
        "    y_train = {k: v[idx_train] for k, v in y_enc.items()}\n",
        "    y_test  = {k: v[idx_test]  for k, v in y_enc.items()}\n",
        "\n",
        "    # Scale features for MLP stability\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test  = scaler.transform(X_test)\n",
        "\n",
        "    train_ds = MultiTaskDataset(X_train, y_train)\n",
        "    test_ds  = MultiTaskDataset(X_test, y_test)\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "    test_loader  = DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    input_dim = X_train.shape[1]\n",
        "\n",
        "    head_dims = {k: len(encoders[k].classes_) for k in y_enc.keys()}\n",
        "    tasks = list(head_dims.keys())\n",
        "\n",
        "    # Loss weights: emphasize context + action heads\n",
        "    loss_weights = {t: 1.0 for t in tasks}\n",
        "    loss_weights[\"context\"] = 2.0\n",
        "    for t in tasks:\n",
        "        if \"pre\" in t or \"post\" in t:\n",
        "            loss_weights[t] = 1.5\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"A2: Multi-task structured classifier (shared MLP trunk + 7 heads)\")\n",
        "    print(\"Tasks:\", tasks)\n",
        "    print(\"Loss weights:\", loss_weights)\n",
        "    print(\"Selecting best config by:\", select_by)\n",
        "\n",
        "    best_score = -1.0\n",
        "    best_state = None\n",
        "    best_cfg = None\n",
        "\n",
        "    for hidden_dims in hidden_grid:\n",
        "        for lr in lr_grid:\n",
        "            model = MultiHeadMLP(\n",
        "                input_dim=input_dim,\n",
        "                hidden_dims=hidden_dims,\n",
        "                dropout=dropout,\n",
        "                head_dims=head_dims\n",
        "            ).to(device)\n",
        "\n",
        "            # Class-weighted CE per head\n",
        "            criterions = {}\n",
        "            for t in tasks:\n",
        "                w = compute_class_weights(y_train[t], head_dims[t], device=device)\n",
        "                criterions[t] = nn.CrossEntropyLoss(weight=w, ignore_index=IGNORE_INDEX)\n",
        "\n",
        "            optim = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "\n",
        "            for _ in range(epochs):\n",
        "                train_one_epoch(model, train_loader, optim, criterions, loss_weights, device)\n",
        "\n",
        "            metrics = evaluate(model, test_loader, tasks, device)\n",
        "\n",
        "            if select_by == \"context\":\n",
        "                score = metrics[\"context\"][\"macro_f1\"]\n",
        "            else:\n",
        "                vals = [metrics[t][\"macro_f1\"] for t in tasks if not np.isnan(metrics[t][\"macro_f1\"])]\n",
        "                score = float(np.mean(vals)) if vals else float(\"nan\")\n",
        "\n",
        "            print(f\"hidden={hidden_dims}, lr={lr:.1e} → score={score:.4f}\")\n",
        "\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
        "                best_cfg = (hidden_dims, lr)\n",
        "\n",
        "    # Reload best\n",
        "    hidden_dims, lr = best_cfg\n",
        "    best_model = MultiHeadMLP(\n",
        "        input_dim=input_dim,\n",
        "        hidden_dims=hidden_dims,\n",
        "        dropout=dropout,\n",
        "        head_dims=head_dims\n",
        "    ).to(device)\n",
        "    best_model.load_state_dict(best_state)\n",
        "\n",
        "    metrics = evaluate(best_model, test_loader, tasks, device)\n",
        "\n",
        "    print(\"\\nBest config:\", {\"hidden_dims\": hidden_dims, \"lr\": lr})\n",
        "    print(\"Best selection score:\", best_score)\n",
        "\n",
        "    # Reports per head\n",
        "    for t in tasks:\n",
        "        le = encoders[t]\n",
        "        y_true = metrics[t][\"y_true\"]\n",
        "        y_pred = metrics[t][\"y_pred\"]\n",
        "        mask = (y_true != IGNORE_INDEX)\n",
        "\n",
        "        print(\"\\n\" + \"-\" * 80)\n",
        "        print(f\"Task: {t}\")\n",
        "        print(f\"Macro-F1: {metrics[t]['macro_f1']:.4f}\")\n",
        "\n",
        "        true_lbl = le.inverse_transform(y_true[mask])\n",
        "        pred_lbl = le.inverse_transform(y_pred[mask])\n",
        "\n",
        "        print(\"\\nClassification report (all classes):\")\n",
        "        K = len(le.classes_)\n",
        "        labels_idx = list(range(K))  # enforce consistent class set\n",
        "\n",
        "        # Use encoded ints for report/CM, so labels line up perfectly\n",
        "        y_true_i = y_true[mask]\n",
        "        y_pred_i = y_pred[mask]\n",
        "\n",
        "        print(classification_report(\n",
        "            y_true_i,\n",
        "            y_pred_i,\n",
        "            labels=labels_idx,\n",
        "            target_names=[str(c) for c in le.classes_],\n",
        "            zero_division=0\n",
        "        ))\n",
        "\n",
        "        print(\"Confusion matrix (all classes):\")\n",
        "        print(confusion_matrix(\n",
        "            y_true_i,\n",
        "            y_pred_i,\n",
        "            labels=labels_idx\n",
        "        ))\n",
        "\n",
        "\n",
        "    return {\n",
        "        \"model\": best_model,\n",
        "        \"scaler\": scaler,\n",
        "        \"encoders\": encoders,\n",
        "        \"tasks\": tasks,\n",
        "        \"best_cfg\": {\"hidden_dims\": hidden_dims, \"lr\": lr, \"score\": best_score},\n",
        "        \"metrics\": metrics,\n",
        "    }\n"
      ],
      "metadata": {
        "id": "WytD3birZeSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Execute training and evaluation\n",
        "\n",
        "This cell runs the full 07.2 experiment, selects the best model, and reports detailed metrics and\n",
        "confusion matrices for all tasks. The results guide interpretation of which communicative variables\n",
        "are acoustically grounded and motivate later modeling stages.\n"
      ],
      "metadata": {
        "id": "x2RBN1BBdsz4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out = run_a2_multitask_mlp(\n",
        "    X_all=X_all,\n",
        "    labels_raw=labels_raw,\n",
        "    hidden_grid=((512,), (512, 256)),  # small grid (A1 suggested bigger isn't always better)\n",
        "    lr_grid=(1e-3, 3e-4),\n",
        "    dropout=0.3,\n",
        "    epochs=30,\n",
        "    batch_size=128,\n",
        "    select_by=\"context\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8C6wOjk3ZhF6",
        "outputId": "81387fe8-c721-4e21-a04d-26f92a4a57b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "A2: Multi-task structured classifier (shared MLP trunk + 7 heads)\n",
            "Tasks: ['emitter', 'addressee', 'context', 'emitter_pre', 'addressee_pre', 'emitter_post', 'addressee_post']\n",
            "Loss weights: {'emitter': 1.0, 'addressee': 1.0, 'context': 2.0, 'emitter_pre': 1.5, 'addressee_pre': 1.5, 'emitter_post': 1.5, 'addressee_post': 1.5}\n",
            "Selecting best config by: context\n",
            "hidden=(512,), lr=1.0e-03 → score=0.3617\n",
            "hidden=(512,), lr=3.0e-04 → score=0.3782\n",
            "hidden=(512, 256), lr=1.0e-03 → score=0.3776\n",
            "hidden=(512, 256), lr=3.0e-04 → score=0.3585\n",
            "\n",
            "Best config: {'hidden_dims': (512,), 'lr': 0.0003}\n",
            "Best selection score: 0.3782362041893505\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Task: emitter\n",
            "Macro-F1: 0.6662\n",
            "\n",
            "Classification report (all classes):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         111       0.69      0.82      0.75       202\n",
            "         210       0.59      0.49      0.54       218\n",
            "         211       0.59      0.58      0.58       205\n",
            "         215       0.56      0.58      0.57       205\n",
            "         216       0.68      0.56      0.61       218\n",
            "         220       0.50      0.58      0.54       186\n",
            "         226       0.84      0.86      0.85       197\n",
            "         228       0.85      0.82      0.83       196\n",
            "         230       0.70      0.70      0.70       194\n",
            "         231       0.68      0.72      0.70       179\n",
            "\n",
            "    accuracy                           0.67      2000\n",
            "   macro avg       0.67      0.67      0.67      2000\n",
            "weighted avg       0.67      0.67      0.66      2000\n",
            "\n",
            "Confusion matrix (all classes):\n",
            "[[165   2   3   2   8   3   2   6   1  10]\n",
            " [  4 107   7  31   5  30   1   1  26   6]\n",
            " [ 11   8 119   9  22  11   1   0   4  20]\n",
            " [  9  22   9 119   2  34   0   1   7   2]\n",
            " [ 23   6  37   3 121   2   3   3   0  20]\n",
            " [  6  19   5  24   2 107   1   0  20   2]\n",
            " [  8   0   0   0   4   0 169  16   0   0]\n",
            " [  7   0   2   1   2   0  23 160   0   1]\n",
            " [  1  14   1  17   3  20   1   1 135   1]\n",
            " [  6   4  19   7   8   5   0   0   1 129]]\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Task: addressee\n",
            "Macro-F1: 0.2247\n",
            "\n",
            "Classification report (all classes):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.49      0.60       204\n",
            "         111       0.00      0.00      0.00         1\n",
            "         120       0.10      0.25      0.14        12\n",
            "         201       0.25      0.50      0.33         2\n",
            "         203       0.00      0.00      0.00         4\n",
            "         204       0.00      0.00      0.00         0\n",
            "         205       0.08      1.00      0.14         2\n",
            "         207       0.78      0.35      0.48       431\n",
            "         208       0.56      0.40      0.47       259\n",
            "         210       0.06      0.25      0.10        16\n",
            "         211       0.09      0.22      0.13        23\n",
            "         212       0.00      0.00      0.00         0\n",
            "         213       0.15      0.22      0.18        36\n",
            "         214       0.00      0.00      0.00         5\n",
            "         215       0.19      0.25      0.22        76\n",
            "         216       0.16      0.31      0.22        32\n",
            "         217       0.14      0.17      0.15         6\n",
            "         218       0.00      0.00      0.00         4\n",
            "         220       0.26      0.42      0.32       103\n",
            "         221       0.47      0.37      0.42       201\n",
            "         224       0.62      0.80      0.70        10\n",
            "         225       0.00      0.00      0.00         1\n",
            "         226       0.14      0.26      0.18        23\n",
            "         228       0.20      0.37      0.26        54\n",
            "         230       0.10      0.32      0.15        37\n",
            "         231       0.22      0.41      0.28        79\n",
            "         232       0.00      0.00      0.00         2\n",
            "         233       0.89      0.76      0.82       377\n",
            "\n",
            "    accuracy                           0.44      2000\n",
            "   macro avg       0.22      0.29      0.22      2000\n",
            "weighted avg       0.59      0.44      0.48      2000\n",
            "\n",
            "Confusion matrix (all classes):\n",
            "[[100   0   1   1   1   0  18   2  11   1   3   3   2   0   5  11   3   0\n",
            "    2   9   4   0   5   3   1   8   0  10]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   1   0   0   0   0]\n",
            " [  0   0   3   0   0   0   0   0   0   1   0   0   1   0   0   1   0   0\n",
            "    0   0   0   0   3   3   0   0   0   0]\n",
            " [  1   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   1   1   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   4   0   0   0   2 151  11  30   8   0   1   0  54   1   0   3\n",
            "   79  10   0   0   2   5  61   6   0   3]\n",
            " [  7   0   3   1   0   0   0   6 104   2  18   0   0   0   0  16   0   1\n",
            "    8  35   0   0   2   4   6  45   0   1]\n",
            " [  0   0   2   0   0   0   0   1   0   4   0   0   0   0   3   0   0   0\n",
            "    4   0   0   0   0   0   2   0   0   0]\n",
            " [  1   0   1   0   0   0   0   0   3   0   5   0   0   0   0   1   0   0\n",
            "    1   5   0   0   0   0   0   6   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   3   0   0   0   0   0   0   0   0   0   8   0   0   0   0   0\n",
            "    0   0   0   0   7  12   0   1   0   5]\n",
            " [  0   0   0   0   0   0   0   0   1   0   0   0   2   0   0   0   0   0\n",
            "    0   0   0   0   1   1   0   0   0   0]\n",
            " [  0   0   1   0   0   0   0   9   0   8   2   0   1   1  19   1   0   1\n",
            "   21   0   0   0   1   0  11   0   0   0]\n",
            " [  2   0   1   0   0   0   0   0   3   0   3   0   1   0   0  10   0   1\n",
            "    0   7   0   0   0   2   0   2   0   0]\n",
            " [  1   0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   1   0\n",
            "    0   0   1   1   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0\n",
            "    1   0   0   1   0   0   1   0   0   0]\n",
            " [  2   0   0   1   1   0   0  15   3   8   1   0   0   0   9   0   0   1\n",
            "   43   0   0   0   0   0  17   2   0   0]\n",
            " [  6   0   1   0   0   0   0   5  35   0  10   0   4   1   0   9   0   0\n",
            "    0  75   0   0   1   3   4  45   0   2]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0\n",
            "    0   0   8   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  2   0   1   0   0   0   0   0   0   0   0   0   4   1   0   0   0   0\n",
            "    0   0   0   0   6   4   0   0   0   5]\n",
            " [  2   0   4   0   0   0   0   0   1   0   0   0   7   1   0   1   0   0\n",
            "    0   0   0   0   7  20   2   0   0   9]\n",
            " [  0   0   0   0   0   0   0   3   1   5   1   0   0   0   6   0   0   1\n",
            "    8   0   0   0   0   0  12   0   0   0]\n",
            " [  2   0   1   0   0   0   0   0  10   1   5   0   1   0   1   7   0   2\n",
            "    1  14   0   0   1   0   1  32   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   1   4   0   0   0   0   1   2   2   0   0  23   2   0   3   0   0\n",
            "    0   3   0   0   6  41   3   0   0 285]]\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Task: context\n",
            "Macro-F1: 0.3782\n",
            "\n",
            "Classification report (all classes):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         8\n",
            "           1       1.00      1.00      1.00         3\n",
            "          10       0.13      0.29      0.18        35\n",
            "          11       0.68      0.53      0.59       552\n",
            "          12       0.81      0.56      0.66       979\n",
            "           2       0.13      0.35      0.19        84\n",
            "           3       0.25      0.54      0.34        74\n",
            "           4       0.15      0.37      0.22        27\n",
            "           5       0.00      0.00      0.00        12\n",
            "           6       0.92      0.91      0.92       145\n",
            "           7       0.07      0.14      0.09        14\n",
            "           9       0.25      0.60      0.35        67\n",
            "\n",
            "    accuracy                           0.55      2000\n",
            "   macro avg       0.37      0.44      0.38      2000\n",
            "weighted avg       0.68      0.55      0.59      2000\n",
            "\n",
            "Confusion matrix (all classes):\n",
            "[[  0   0   0   3   0   1   2   1   0   0   0   1]\n",
            " [  0   3   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0  10  15   3   2   2   0   0   0   0   3]\n",
            " [  2   0  45 290  66  19  78  20   1   5   2  24]\n",
            " [  8   0  19  83 545 152  26  29  18   4  22  73]\n",
            " [  1   0   1   3  31  29   4   1   5   0   2   7]\n",
            " [  0   0   0  18   2   4  40   0   2   2   1   5]\n",
            " [  0   0   1   4   5   0   2  10   0   0   0   5]\n",
            " [  0   0   0   2   5   0   2   2   0   0   0   1]\n",
            " [  0   0   0   6   5   0   1   1   0 132   0   0]\n",
            " [  0   0   0   1   5   4   1   0   0   0   2   1]\n",
            " [  0   0   0   3  10   9   3   1   0   0   1  40]]\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Task: emitter_pre\n",
            "Macro-F1: 0.4502\n",
            "\n",
            "Classification report (all classes):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.41      0.50      0.45        50\n",
            "           1       0.19      0.40      0.25        53\n",
            "           2       0.96      0.86      0.91      1811\n",
            "           3       0.13      0.33      0.19        86\n",
            "\n",
            "    accuracy                           0.81      2000\n",
            "   macro avg       0.42      0.52      0.45      2000\n",
            "weighted avg       0.89      0.81      0.85      2000\n",
            "\n",
            "Confusion matrix (all classes):\n",
            "[[  25    4   12    9]\n",
            " [   2   21   17   13]\n",
            " [  22   72 1555  162]\n",
            " [  12   15   31   28]]\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Task: addressee_pre\n",
            "Macro-F1: 0.5507\n",
            "\n",
            "Classification report (all classes):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.85      0.78       129\n",
            "           1       0.26      0.54      0.35        61\n",
            "           2       0.95      0.80      0.87      1707\n",
            "           3       0.14      0.38      0.20       103\n",
            "\n",
            "    accuracy                           0.78      2000\n",
            "   macro avg       0.52      0.64      0.55      2000\n",
            "weighted avg       0.87      0.78      0.81      2000\n",
            "\n",
            "Confusion matrix (all classes):\n",
            "[[ 110    2   13    4]\n",
            " [   1   33   14   13]\n",
            " [  38   76 1370  223]\n",
            " [   4   18   42   39]]\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Task: emitter_post\n",
            "Macro-F1: 0.4114\n",
            "\n",
            "Classification report (all classes):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.43      0.57      0.49        46\n",
            "           1       0.00      0.00      0.00         1\n",
            "           2       0.39      0.59      0.47       147\n",
            "           3       0.95      0.81      0.87      1710\n",
            "           4       0.15      0.43      0.22        96\n",
            "\n",
            "    accuracy                           0.77      2000\n",
            "   macro avg       0.39      0.48      0.41      2000\n",
            "weighted avg       0.86      0.77      0.80      2000\n",
            "\n",
            "Confusion matrix (all classes):\n",
            "[[  26    0    4    7    9]\n",
            " [   0    0    0    1    0]\n",
            " [   5    0   87   23   32]\n",
            " [  23    0  117 1381  189]\n",
            " [   7    0   13   35   41]]\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Task: addressee_post\n",
            "Macro-F1: 0.5056\n",
            "\n",
            "Classification report (all classes):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.88      0.81       129\n",
            "           1       0.00      0.00      0.00         0\n",
            "           2       0.12      0.37      0.18        38\n",
            "           3       0.96      0.78      0.86      1751\n",
            "           4       0.11      0.41      0.18        82\n",
            "\n",
            "    accuracy                           0.76      2000\n",
            "   macro avg       0.39      0.49      0.40      2000\n",
            "weighted avg       0.89      0.76      0.81      2000\n",
            "\n",
            "Confusion matrix (all classes):\n",
            "[[ 113    0    2   13    1]\n",
            " [   0    0    0    0    0]\n",
            " [   0    0   14   16    8]\n",
            " [  35    0   92 1365  259]\n",
            " [   2    0   13   33   34]]\n"
          ]
        }
      ]
    }
  ]
}