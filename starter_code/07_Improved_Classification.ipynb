{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 07 â€“ Improved Classification with Grid Search\n",
        "\n",
        "This notebook improves on the simple baselines in `06_Baseline_Classification.ipynb` by:\n",
        "\n",
        "- Using **richer feature representations** (AST embeddings plus discrete token histograms).\n",
        "- Performing **hyperparameter tuning** via `GridSearchCV` instead of a single fixed logistic-regression configuration.\n",
        "- Using **separate classification functions** for emitter and context prediction, with appropriate handling of class imbalance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(PosixPath('/Users/mahikacalyanakoti/Downloads/College/Year4/Year4Sem1/ESE5460/bat-llm/starter_code'),\n",
              " PosixPath('/Users/mahikacalyanakoti/Downloads/College/Year4/Year4Sem1/ESE5460/bat-llm/starter_code/derived/ast_features'),\n",
              " PosixPath('/Users/mahikacalyanakoti/Downloads/College/Year4/Year4Sem1/ESE5460/bat-llm/starter_code/derived/tokens/k_means'),\n",
              " PosixPath('/Users/mahikacalyanakoti/Downloads/College/Year4/Year4Sem1/ESE5460/bat-llm/starter_code/derived/tokens/vqvae'),\n",
              " PosixPath('/Users/mahikacalyanakoti/Downloads/College/Year4/Year4Sem1/ESE5460/bat-llm/starter_code/annotations_10k.csv'))"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from pathlib import Path\n",
        "from typing import List, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# Paths (assume this notebook is run from starter_code/)\n",
        "ROOT = Path.cwd().resolve()\n",
        "DATA_DIR = ROOT / \"data\"\n",
        "DERIVED_DIR = ROOT / \"derived\"\n",
        "AUDIO_DIR = DATA_DIR / \"audio\"\n",
        "MELS_48K_DIR = DERIVED_DIR / \"mels_48k\"\n",
        "TOKENS_DIR = DERIVED_DIR / \"tokens\"\n",
        "AST_DIR = DERIVED_DIR / \"ast_features\"\n",
        "KMEANS_DIR = TOKENS_DIR / \"k_means\"\n",
        "VQ_TOKENS_DIR = TOKENS_DIR / \"vqvae\"\n",
        "ANNOT_PATH = ROOT / \"annotations_10k.csv\"\n",
        "\n",
        "ROOT, AST_DIR, KMEANS_DIR, VQ_TOKENS_DIR, ANNOT_PATH\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load annotations\n",
        "\n",
        "We reuse the 10k annotations file and check that the key columns are present.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Emitter</th>\n",
              "      <th>File Name</th>\n",
              "      <th>FileID</th>\n",
              "      <th>Addressee</th>\n",
              "      <th>Context</th>\n",
              "      <th>Emitter pre-vocalization action</th>\n",
              "      <th>Addressee pre-vocalization action</th>\n",
              "      <th>Emitter post-vocalization action</th>\n",
              "      <th>Addressee post-vocalization action</th>\n",
              "      <th>Start sample</th>\n",
              "      <th>End sample</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>216</td>\n",
              "      <td>69809.wav</td>\n",
              "      <td>233219</td>\n",
              "      <td>221</td>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>590672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>215</td>\n",
              "      <td>71889.wav</td>\n",
              "      <td>237330</td>\n",
              "      <td>220</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>328528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>216</td>\n",
              "      <td>46690.wav</td>\n",
              "      <td>173649</td>\n",
              "      <td>231</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>467792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>230</td>\n",
              "      <td>85411.wav</td>\n",
              "      <td>268012</td>\n",
              "      <td>221</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>475984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>215</td>\n",
              "      <td>45609.wav</td>\n",
              "      <td>170616</td>\n",
              "      <td>220</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>336720</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Emitter  File Name  FileID  Addressee  Context  \\\n",
              "0      216  69809.wav  233219        221       11   \n",
              "1      215  71889.wav  237330        220       12   \n",
              "2      216  46690.wav  173649        231       12   \n",
              "3      230  85411.wav  268012        221       12   \n",
              "4      215  45609.wav  170616        220       12   \n",
              "\n",
              "   Emitter pre-vocalization action  Addressee pre-vocalization action  \\\n",
              "0                                2                                  3   \n",
              "1                                2                                  2   \n",
              "2                                2                                  2   \n",
              "3                                2                                  2   \n",
              "4                                2                                  2   \n",
              "\n",
              "   Emitter post-vocalization action  Addressee post-vocalization action  \\\n",
              "0                                 3                                   3   \n",
              "1                                 3                                   3   \n",
              "2                                 3                                   3   \n",
              "3                                 3                                   3   \n",
              "4                                 3                                   3   \n",
              "\n",
              "   Start sample  End sample  \n",
              "0             1      590672  \n",
              "1             1      328528  \n",
              "2             1      467792  \n",
              "3             1      475984  \n",
              "4             1      336720  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def load_annotations(path: Path) -> pd.DataFrame:\n",
        "    if not path.exists():\n",
        "        raise FileNotFoundError(f\"annotations file not found at {path}\")\n",
        "    ann = pd.read_csv(path)\n",
        "    required_cols = [\"Emitter\", \"File Name\", \"Context\"]\n",
        "    missing = [c for c in required_cols if c not in ann.columns]\n",
        "    if missing:\n",
        "        raise ValueError(f\"annotations_10k.csv missing columns: {missing}\")\n",
        "    return ann\n",
        "\n",
        "ann = load_annotations(ANNOT_PATH)\n",
        "ann.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Collect combined features\n",
        "\n",
        "We build one feature vector per annotated example by combining:\n",
        "\n",
        "- **AST pooled embeddings** (`derived/ast_features/ast_<stem>.npy`).\n",
        "- **wav2vec2 + k-means token histograms** (`derived/tokens/k_means/w2v_kmeans_<stem>.npy`).\n",
        "- **VQ-VAE code histograms** (`derived/tokens/vqvae/vqvae_<stem>.npy`).\n",
        "\n",
        "You can toggle which components are used; by default we use all three for richer representations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Built combined features for 10000 examples; dim=1152 (skipped 0 with missing components).\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "((10000, 1152), 10000, 10000)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def _load_ast_vector(stem: str) -> np.ndarray | None:\n",
        "    ast_path = AST_DIR / f\"ast_{stem}.npy\"\n",
        "    if not ast_path.exists():\n",
        "        return None\n",
        "    vec = np.load(ast_path)\n",
        "    return np.asarray(vec, dtype=np.float32).reshape(-1)\n",
        "\n",
        "\n",
        "def _load_kmeans_hist(stem: str, n_clusters: int = 128) -> np.ndarray | None:\n",
        "    tok_path = KMEANS_DIR / f\"w2v_kmeans_{stem}.npy\"\n",
        "    if not tok_path.exists():\n",
        "        return None\n",
        "    tokens = np.load(tok_path).astype(int)\n",
        "    hist = np.bincount(tokens, minlength=n_clusters).astype(np.float32)\n",
        "    total = hist.sum()\n",
        "    if total > 0:\n",
        "        hist /= total  # normalize to frequencies\n",
        "    return hist\n",
        "\n",
        "\n",
        "def _load_vqvae_hist(stem: str, n_codes: int = 256) -> np.ndarray | None:\n",
        "    tok_path = VQ_TOKENS_DIR / f\"vqvae_{stem}.npy\"\n",
        "    if not tok_path.exists():\n",
        "        return None\n",
        "    tokens = np.load(tok_path).astype(int)\n",
        "    hist = np.bincount(tokens, minlength=n_codes).astype(np.float32)\n",
        "    total = hist.sum()\n",
        "    if total > 0:\n",
        "        hist /= total\n",
        "    return hist\n",
        "\n",
        "\n",
        "def collect_features(\n",
        "    ann: pd.DataFrame,\n",
        "    use_ast: bool = True,\n",
        "    use_kmeans_tokens: bool = True,\n",
        "    use_vqvae_tokens: bool = True,\n",
        ") -> Tuple[np.ndarray, List[str], List[str]]:\n",
        "    \"\"\"Collect feature matrix and labels for all examples with available features.\"\"\"\n",
        "\n",
        "    stems = ann[\"File Name\"].apply(lambda s: Path(str(s)).stem)\n",
        "\n",
        "    X_list: List[np.ndarray] = []\n",
        "    emitters: List[str] = []\n",
        "    contexts: List[str] = []\n",
        "\n",
        "    missing_any = 0\n",
        "\n",
        "    for fn, stem, emitter, ctx in zip(\n",
        "        ann[\"File Name\"], stems, ann[\"Emitter\"], ann[\"Context\"],\n",
        "    ):\n",
        "        parts: List[np.ndarray] = []\n",
        "\n",
        "        if use_ast:\n",
        "            ast_vec = _load_ast_vector(stem)\n",
        "            if ast_vec is None:\n",
        "                missing_any += 1\n",
        "                continue\n",
        "            parts.append(ast_vec)\n",
        "\n",
        "        if use_kmeans_tokens:\n",
        "            km_hist = _load_kmeans_hist(stem)\n",
        "            if km_hist is None:\n",
        "                missing_any += 1\n",
        "                continue\n",
        "            parts.append(km_hist)\n",
        "\n",
        "        if use_vqvae_tokens:\n",
        "            vq_hist = _load_vqvae_hist(stem)\n",
        "            if vq_hist is None:\n",
        "                missing_any += 1\n",
        "                continue\n",
        "            parts.append(vq_hist)\n",
        "\n",
        "        if not parts:\n",
        "            # No features requested\n",
        "            continue\n",
        "\n",
        "        feat_vec = np.concatenate(parts).astype(np.float32)\n",
        "        X_list.append(feat_vec)\n",
        "        emitters.append(str(emitter))\n",
        "        contexts.append(str(ctx))\n",
        "\n",
        "    if not X_list:\n",
        "        raise RuntimeError(\n",
        "            \"No feature vectors constructed. Make sure 05_Tokenization_Strategies.ipynb \"\n",
        "            \"has been run to generate AST embeddings and token files.\"\n",
        "        )\n",
        "\n",
        "    X = np.vstack(X_list)\n",
        "    print(\n",
        "        f\"Built combined features for {X.shape[0]} examples; \"\n",
        "        f\"dim={X.shape[1]} (skipped {missing_any} with missing components).\"\n",
        "    )\n",
        "    return X, emitters, contexts\n",
        "\n",
        "\n",
        "X_all, y_emitters_all, y_contexts_all = collect_features(\n",
        "    ann,\n",
        "    use_ast=True,\n",
        "    use_kmeans_tokens=True,\n",
        "    use_vqvae_tokens=True,\n",
        ")\n",
        "X_all.shape, len(y_emitters_all), len(y_contexts_all)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helper: emitter classification with grid search\n",
        "\n",
        "We fit a logistic-regression classifier on top of standardized features and use `GridSearchCV`\n",
        "with stratified folds to pick the best hyperparameters for the emitter task.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_emitter_grid_search(\n",
        "    X: np.ndarray,\n",
        "    y_emitters: List[str],\n",
        "    test_size: float = 0.2,\n",
        "    random_state: int = 42,\n",
        "    n_splits: int = 5,\n",
        ") -> None:\n",
        "    \"\"\"Train an improved emitter classifier with hyperparameter search.\"\"\"\n",
        "\n",
        "    y_arr = np.asarray(y_emitters, dtype=object)\n",
        "\n",
        "    le = LabelEncoder()\n",
        "    y_enc = le.fit_transform(y_arr)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X,\n",
        "        y_enc,\n",
        "        test_size=test_size,\n",
        "        stratify=y_enc,\n",
        "        random_state=random_state,\n",
        "    )\n",
        "\n",
        "    pipe = Pipeline(\n",
        "        steps=[\n",
        "            (\"scaler\", StandardScaler()),\n",
        "            (\n",
        "                \"clf\",\n",
        "                LogisticRegression(\n",
        "                    max_iter=2000,\n",
        "                    n_jobs=-1,\n",
        "                ),\n",
        "            ),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    param_grid = {\n",
        "        \"clf__C\": [0.1, 1.0, 10.0],\n",
        "        \"clf__class_weight\": [None, \"balanced\"],\n",
        "        \"clf__solver\": [\"lbfgs\"],\n",
        "        \"clf__penalty\": [\"l2\"],\n",
        "    }\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "\n",
        "    grid = GridSearchCV(\n",
        "        pipe,\n",
        "        param_grid=param_grid,\n",
        "        scoring=\"f1_macro\",\n",
        "        n_jobs=-1,\n",
        "        cv=cv,\n",
        "        refit=True,\n",
        "        verbose=1,\n",
        "    )\n",
        "\n",
        "    grid.fit(X_train, y_train)\n",
        "\n",
        "    best_clf = grid.best_estimator_\n",
        "\n",
        "    y_pred = best_clf.predict(X_test)\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"Improved baseline: Emitter classification (AST + tokens + logistic regression)\")\n",
        "    print(\"Best CV macro-F1:\", grid.best_score_)\n",
        "    print(\"Best params:\", grid.best_params_)\n",
        "\n",
        "    classes = le.classes_\n",
        "    if classes is None:\n",
        "        raise RuntimeError(\"LabelEncoder.classes_ is None; encoder was not fitted correctly.\")\n",
        "\n",
        "    print(\"Classes:\", list(classes))\n",
        "    print(\"\\nClassification report (test set):\")\n",
        "    print(classification_report(y_test, y_pred, target_names=classes))\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    print(\"Confusion matrix (rows=true, cols=pred):\")\n",
        "    print(cm)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helper: context classification with grid search\n",
        "\n",
        "We define a separate function for the context task, using a similar pipeline but\n",
        "emphasizing macro-F1 and allowing `class_weight='balanced'` to better handle\n",
        "class imbalance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_context_grid_search(\n",
        "    X: np.ndarray,\n",
        "    y_contexts: List[str],\n",
        "    test_size: float = 0.2,\n",
        "    random_state: int = 42,\n",
        "    n_splits: int = 5,\n",
        ") -> None:\n",
        "    \"\"\"Train an improved context classifier with hyperparameter search.\"\"\"\n",
        "\n",
        "    y_arr = np.asarray(y_contexts, dtype=object)\n",
        "\n",
        "    le = LabelEncoder()\n",
        "    y_enc = le.fit_transform(y_arr)\n",
        "\n",
        "    # If there is only a single unique context label, skip training.\n",
        "    classes = le.classes_\n",
        "    if classes is None or len(classes) < 2:\n",
        "        print(\"[info] Skipping context baseline: only one unique context label found.\")\n",
        "        return\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X,\n",
        "        y_enc,\n",
        "        test_size=test_size,\n",
        "        stratify=y_enc,\n",
        "        random_state=random_state,\n",
        "    )\n",
        "\n",
        "    pipe = Pipeline(\n",
        "        steps=[\n",
        "            (\"scaler\", StandardScaler()),\n",
        "            (\n",
        "                \"clf\",\n",
        "                LogisticRegression(\n",
        "                    max_iter=2000,\n",
        "                    n_jobs=-1,\n",
        "                ),\n",
        "            ),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    param_grid = {\n",
        "        \"clf__C\": [0.1, 1.0, 10.0],\n",
        "        \"clf__class_weight\": [None, \"balanced\"],\n",
        "        \"clf__solver\": [\"lbfgs\"],\n",
        "        \"clf__penalty\": [\"l2\"],\n",
        "    }\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "\n",
        "    grid = GridSearchCV(\n",
        "        pipe,\n",
        "        param_grid=param_grid,\n",
        "        scoring=\"f1_macro\",\n",
        "        n_jobs=-1,\n",
        "        cv=cv,\n",
        "        refit=True,\n",
        "        verbose=1,\n",
        "    )\n",
        "\n",
        "    grid.fit(X_train, y_train)\n",
        "\n",
        "    best_clf = grid.best_estimator_\n",
        "\n",
        "    y_pred = best_clf.predict(X_test)\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"Improved baseline: Context classification (AST + tokens + logistic regression)\")\n",
        "    print(\"Best CV macro-F1:\", grid.best_score_)\n",
        "    print(\"Best params:\", grid.best_params_)\n",
        "\n",
        "    classes = le.classes_\n",
        "    if classes is None:\n",
        "        raise RuntimeError(\"LabelEncoder.classes_ is None; encoder was not fitted correctly.\")\n",
        "\n",
        "    print(\"Classes:\", list(classes))\n",
        "    print(\"\\nClassification report (test set):\")\n",
        "    print(classification_report(y_test, y_pred, target_names=classes))\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    print(\"Confusion matrix (rows=true, cols=pred):\")\n",
        "    print(cm)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run improved baselines\n",
        "\n",
        "Now we run the improved emitter and context classifiers on the combined features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
            "\n",
            "================================================================================\n",
            "Improved baseline: Emitter classification (AST + tokens + logistic regression)\n",
            "Best CV macro-F1: 0.6333754654976389\n",
            "Best params: {'clf__C': 0.1, 'clf__class_weight': None, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}\n",
            "Classes: ['111', '210', '211', '215', '216', '220', '226', '228', '230', '231']\n",
            "\n",
            "Classification report (test set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         111       0.78      0.82      0.80       200\n",
            "         210       0.46      0.46      0.46       200\n",
            "         211       0.52      0.54      0.53       200\n",
            "         215       0.56      0.49      0.52       200\n",
            "         216       0.61      0.65      0.63       200\n",
            "         220       0.54      0.57      0.55       200\n",
            "         226       0.83      0.86      0.85       200\n",
            "         228       0.88      0.81      0.85       200\n",
            "         230       0.69      0.64      0.66       200\n",
            "         231       0.63      0.67      0.65       200\n",
            "\n",
            "    accuracy                           0.65      2000\n",
            "   macro avg       0.65      0.65      0.65      2000\n",
            "weighted avg       0.65      0.65      0.65      2000\n",
            "\n",
            "Confusion matrix (rows=true, cols=pred):\n",
            "[[165   0   6   2   7   2   7   4   0   7]\n",
            " [  1  92   7  27  10  34   0   0  18  11]\n",
            " [  9   7 107   6  26   8   1   0   5  31]\n",
            " [  4  31  17  98   2  27   4   1   9   7]\n",
            " [ 12   4  27   1 130   0   2   1   4  19]\n",
            " [  3  32  12  21   3 114   0   0  15   0]\n",
            " [  7   0   0   1   3   0 173  16   0   0]\n",
            " [  9   1   2   0   4   1  19 163   0   1]\n",
            " [  0  25   3  16   8  20   0   0 127   1]\n",
            " [  1   6  26   2  20   5   2   0   5 133]]\n",
            "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
            "\n",
            "================================================================================\n",
            "Improved baseline: Context classification (AST + tokens + logistic regression)\n",
            "Best CV macro-F1: 0.33151063210496884\n",
            "Best params: {'clf__C': 0.1, 'clf__class_weight': None, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}\n",
            "Classes: ['0', '1', '10', '11', '12', '2', '3', '4', '5', '6', '7', '9']\n",
            "\n",
            "Classification report (test set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         8\n",
            "           1       1.00      0.67      0.80         3\n",
            "          10       0.05      0.03      0.04        35\n",
            "          11       0.66      0.67      0.67       552\n",
            "          12       0.73      0.83      0.78       979\n",
            "           2       0.17      0.08      0.11        84\n",
            "           3       0.40      0.28      0.33        74\n",
            "           4       0.20      0.07      0.11        27\n",
            "           5       0.00      0.00      0.00        12\n",
            "           6       0.91      0.86      0.88       145\n",
            "           7       0.33      0.07      0.12        14\n",
            "           9       0.38      0.30      0.33        67\n",
            "\n",
            "    accuracy                           0.68      2000\n",
            "   macro avg       0.40      0.32      0.35      2000\n",
            "weighted avg       0.65      0.68      0.66      2000\n",
            "\n",
            "Confusion matrix (rows=true, cols=pred):\n",
            "[[  0   0   0   5   3   0   0   0   0   0   0   0]\n",
            " [  0   2   0   1   0   0   0   0   0   0   0   0]\n",
            " [  0   0   1  22   6   2   2   0   0   1   0   1]\n",
            " [  0   0  14 371 132   5  17   2   0   6   0   5]\n",
            " [  0   0   5  97 814  26   8   4   1   4   2  18]\n",
            " [  0   0   0   7  64   7   0   0   2   0   0   4]\n",
            " [  0   0   0  30  16   0  21   0   1   2   0   4]\n",
            " [  0   0   1  10  14   0   0   2   0   0   0   0]\n",
            " [  0   0   0   0  10   0   1   0   0   0   0   1]\n",
            " [  0   0   0  11   7   0   1   1   0 125   0   0]\n",
            " [  0   0   0   2  11   0   0   0   0   0   1   0]\n",
            " [  0   0   0   6  36   1   3   1   0   0   0  20]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/mahikacalyanakoti/Downloads/College/Year4/Year4Sem1/ESE5460/bat-llm/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
            "/Users/mahikacalyanakoti/Downloads/College/Year4/Year4Sem1/ESE5460/bat-llm/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
            "/Users/mahikacalyanakoti/Downloads/College/Year4/Year4Sem1/ESE5460/bat-llm/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
          ]
        }
      ],
      "source": [
        "# Emitter classification\n",
        "run_emitter_grid_search(X_all, y_emitters_all)\n",
        "\n",
        "# Context classification\n",
        "run_context_grid_search(X_all, y_contexts_all)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
